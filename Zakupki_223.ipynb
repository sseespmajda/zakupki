{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rajDyGemoV8Q"
   },
   "source": [
    "# Zakupki website scraping for Piotr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfVriCvQPi8u"
   },
   "source": [
    "The aim of this notebook is to scrape details of each contract hosted on the Russian Zakupki public sector contract awarding website.\n",
    "\n",
    "The input for this project will be the Zakupki URL. This code can be run on different dates to pull fresh contract data.\n",
    "\n",
    "Method:\n",
    "1.   Identify the number of pages of contracts to be scraped (using the contract filters provided).\n",
    "2.   Iterate through each page, scraping the registration number of each contract.\n",
    "3.   Access the website for each contract by placing the registraion number in the URL.\n",
    "4.   Scrape the details for each contract and add them to a list of Contracts dataclasses.\n",
    "5.   Format these Contract objects as a dataframe and output the dataframe to a csv file.\n",
    "\n",
    "\n",
    "The output of this project will be the CSV file, with each row representing a new contract from the webstie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9O34U-48RLCa"
   },
   "source": [
    "### Section 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "EkywDpTl3_lN"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from urllib3.util import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "from dateutil import parser\n",
    "from threading import Thread\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "import logging\n",
    "import http.client\n",
    "from functools import lru_cache\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import math\n",
    "from os import walk\n",
    "import json\n",
    "import numpy as np\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding the memory leak\n",
    "\n",
    "from collections import Counter\n",
    "import linecache\n",
    "import os\n",
    "import tracemalloc\n",
    "\n",
    "def display_top(snapshot, key_type='lineno', limit=3):\n",
    "    snapshot = snapshot.filter_traces((\n",
    "        tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "        tracemalloc.Filter(False, \"<unknown>\"),\n",
    "    ))\n",
    "    top_stats = snapshot.statistics(key_type)\n",
    "\n",
    "    print(\"Top %s lines\" % limit)\n",
    "    for index, stat in enumerate(top_stats[:limit], 1):\n",
    "        frame = stat.traceback[0]\n",
    "        # replace \"/path/to/module/file.py\" with \"module/file.py\"\n",
    "        filename = os.sep.join(frame.filename.split(os.sep)[-2:])\n",
    "        print(\"#%s: %s:%s: %.1f KiB\"\n",
    "              % (index, filename, frame.lineno, stat.size / 1024))\n",
    "        line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "        if line:\n",
    "            print('    %s' % line)\n",
    "\n",
    "    other = top_stats[limit:]\n",
    "    if other:\n",
    "        size = sum(stat.size for stat in other)\n",
    "        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "    total = sum(stat.size for stat in top_stats)\n",
    "    print(\"Total allocated size: %.1f KiB\" % (total / 1024))\n",
    "\n",
    "\n",
    "tracemalloc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ohoWQEyyCpkk"
   },
   "outputs": [],
   "source": [
    "logging = False\n",
    "\n",
    "if logging:\n",
    "\n",
    "    http.client.HTTPConnection.debuglevel = 1\n",
    "\n",
    "    # You must initialize logging, otherwise you'll not see debug output.\n",
    "    logging.basicConfig()\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "    requests_log = logging.getLogger(\"requests.packages.urllib3\")\n",
    "    requests_log.setLevel(logging.DEBUG)\n",
    "    requests_log.propagate = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJWBR30Apf9y"
   },
   "source": [
    "### Section 2: Determine Number of pages to scrape\n",
    "Test connection to the website and determine number of pages to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "IxF2lQm5Vq_8"
   },
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "# @lru_cache(maxsize=None)\n",
    "def getPage(tempURL):\n",
    "  # If User-Agent is not set to custom, the website will know a Python script is accessing it and block some of the request\n",
    "\n",
    "  response = session.get(tempURL, headers={'User-Agent': 'Custom'})\n",
    "  return BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vqetG6kV0HFi",
    "outputId": "d351bc31-6ef2-4d6c-89a8-bf9234b503dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 91 dates\n"
     ]
    }
   ],
   "source": [
    "# Getting the dates we want to scrape.\n",
    "\n",
    "#url=\"https://zakupki.gov.ru/epz/contractfz223/search/results.html?morphology=on&sortDirection=false&recordsPerPage=_50&showLotsInfoHidden=false&statuses_0=on&statuses_1=on&statuses=0%2C1&priceFrom=1000000&currencyId=-1&contract223DateFrom={}&contract223DateTo={}&sortBy=BY_UPDATE_DATE&pageNumber={}&customerPlace=5277383\"\n",
    "url=\"https://zakupki.gov.ru/epz/order/extendedsearch/results.html?morphology=on&sortBy=UPDATE_DATE&sortDirection=false&recordsPerPage=_500&showLotsInfoHidden=false&fz223=on&pc=on&priceContractAdvantages44IdNameHidden=%7B%7D&priceContractAdvantages94IdNameHidden=%7B%7D&priceFromGeneral=1000000&priceFromGWS=%D0%9C%D0%B8%D0%BD%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F%D1%86%D0%B5%D0%BD%D0%B0&priceFromUnitGWS=%D0%9C%D0%B8%D0%BD%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F%D1%86%D0%B5%D0%BD%D0%B0&priceToGWS=%D0%9C%D0%B0%D0%BA%D1%81%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F%D1%86%D0%B5%D0%BD%D0%B0&priceToUnitGWS=%D0%9C%D0%B0%D0%BA%D1%81%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F%D1%86%D0%B5%D0%BD%D0%B0&currencyIdGeneral=-1&publishDateFrom={}&publishDateTo={}&pageNumber={}&customerPlace=5277383&selectedSubjectsIdNameHidden=%7B%7D&okdpGroupIdsIdNameHidden=%7B%7D&koksIdsIdNameHidden=%7B%7D&OrderPlacementSmallBusinessSubject=on&OrderPlacementRnpData=on&OrderPlacementExecutionRequirement=on&orderPlacement94_0=0&orderPlacement94_1=0&orderPlacement94_2=0&contractPriceCurrencyId=-1&budgetLevelIdNameHidden=%7B%7D&nonBudgetTypesIdNameHidden=%7B%7D\"\n",
    "startDate = date(2016, 4, 1)\n",
    "endDate = date(2016, 6, 30)\n",
    "days = timedelta(days=1)\n",
    "\n",
    "startDateBefore = startDate\n",
    "\n",
    "calendar=[]\n",
    "\n",
    "while startDate<=endDate:\n",
    "  calendar.append(startDate.strftime('%d.%m.%Y'))\n",
    "  startDate+=days\n",
    "\n",
    "print(\"Created {} dates\".format(len(calendar)))\n",
    "# startDate = date(2016, 1, 1)\n",
    "# endDate = date(2016, 1, 31)\n",
    "# days = timedelta(days=1)\n",
    "\n",
    "# startDateBefore = startDate\n",
    "\n",
    "# calendar=[]\n",
    "\n",
    "# while startDate<=endDate:\n",
    "#   calendar.append(startDate.strftime('%d.%m.%Y'))\n",
    "#   startDate+=days\n",
    "\n",
    "# print(\"Created {} dates\".format(len(calendar)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-Ol6Rbipi4N"
   },
   "source": [
    "\n",
    "### Section 3: Scrape each registration number\n",
    "\n",
    "Scrape the reg numbers of each contract, so they can be accessed individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Page:\n",
    "\n",
    "    def __init__(self, day, pageNum, pagefile):\n",
    "\n",
    "        self.day = day\n",
    "        self.pageNum = pageNum\n",
    "        self.pagefile = pagefile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMAKE FOR TENDERS, NOT CONTRACT REGISTRY FOR MORE DATA ###\n",
    "\n",
    "def getContracts(page):\n",
    "# url=\"https://zakupki.gov.ru/epz/order/extendedsearch/results.html?morphology=on&search-filter=%D0%94%D0%B0%D1%82%D0%B5+%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%89%D0%B5%D0%BD%D0%B8%D1%8F&pageNumber=1&sortDirection=false&recordsPerPage=_500&showLotsInfoHidden=false&sortBy=UPDATE_DATE&fz223=on&pc=on&priceFromGeneral=1000000&currencyIdGeneral=-1&publishDateFrom=01.01.2016&publishDateTo=08.01.2016&customerPlace=5277383&customerPlaceCodes=66000000000&OrderPlacementSmallBusinessSubject=on&OrderPlacementRnpData=on&OrderPlacementExecutionRequirement=on&orderPlacement94_0=0&orderPlacement94_1=0&orderPlacement94_2=0\"\n",
    "# soup=getPage(url)\n",
    "\n",
    " \n",
    "    # Obtain a list of all the sections of HTML containing a contract in the web page\n",
    "    listOfContracts = page.find_all(\"div\", {\"class\": \"registry-entry__header-mid__number\"})\n",
    "    regNumbersList=[]\n",
    "\n",
    "    for contract in listOfContracts:\n",
    "                regNum = contract.find(\"a\")['href'].split(\"Id=\")[1] ### changed from =id?\n",
    "                regNumbersList.append(regNum)\n",
    "                \n",
    "    return regNumbersList\n",
    "# print(regNumbersList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress(idx, data):\n",
    "\n",
    "    x_ = int(((idx+1) * 100) / len(data))\n",
    "    y_ = idx % math.ceil(len(data) / 10)\n",
    "    \n",
    "    print(\" ----\\n{}% completed\\n----\".format(x_)) if y_ == 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "seJyyDBCFLGl"
   },
   "outputs": [],
   "source": [
    "# Getting the web page for all the contracts for each date in the range we want to scrape.\n",
    "\n",
    "regNumbersDict = {}\n",
    "\n",
    "def getRegNumbersForDate(i, day):\n",
    "\n",
    "  if day in regNumbersDict:\n",
    "    return\n",
    "\n",
    "  tempURL = url.format(day, day, 1)\n",
    "\n",
    "  # print(tempURL)\n",
    "\n",
    "  page = getPage(tempURL)\n",
    "\n",
    "  # Scrape the max number of pages\n",
    "  try:\n",
    "    maxPageNum = int(page.select('a[data-pagenumber]')[-2].find(\"span\").text)\n",
    "    print(\"{} pages for this day\".format(maxPageNum))\n",
    "  except:\n",
    "    maxPageNum = 1\n",
    "\n",
    "\n",
    "  # Leave my variable names alone :(\n",
    "  totalRegNumbersForThisDay = 0\n",
    "\n",
    "  for i in range(1, maxPageNum+1):\n",
    "\n",
    "    # Creating a temporary URL for each page containing contracts\n",
    "    tempPageURL = url.format(day, day, i)\n",
    "\n",
    "    # Request the page and format it as a BeautifulSoup object so that we can perform scrapings\n",
    "    page = getPage(tempPageURL)\n",
    "\n",
    "    regNumbersList = getContracts(page)\n",
    "\n",
    "    totalRegNumbersForThisDay += len(regNumbersList)\n",
    "\n",
    "    regNumbersDict[day] = regNumbersList\n",
    "\n",
    "\n",
    "  print(\"Fetched day {} had {} contracts \\n\".format(day, totalRegNumbersForThisDay), end='')\n",
    "\n",
    "  del page\n",
    "  del regNumbersList\n",
    "\n",
    "  progress(i, calendar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched day 03.04.2016 had 8 contracts \n",
      "Fetched day 02.04.2016 had 0 contracts \n",
      "Fetched day 09.04.2016 had 1 contracts \n",
      "Fetched day 16.04.2016 had 0 contracts \n",
      "Fetched day 23.04.2016 had 3 contracts \n",
      "Fetched day 17.04.2016 had 1 contracts \n",
      "Fetched day 01.05.2016 had 0 contracts \n",
      "Fetched day 07.05.2016 had 0 contracts \n",
      "Fetched day 22.05.2016 had 3 contracts \n",
      "Fetched day 07.04.2016 had 51 contracts \n",
      "Fetched day 21.05.2016 had 1 contracts \n",
      "Fetched day 05.04.2016 had 39 contracts \n",
      "Fetched day 10.04.2016 had 2 contracts \n",
      "Fetched day 19.04.2016 had 34 contracts \n",
      "Fetched day 04.04.2016 had 46 contracts \n",
      "Fetched day 11.04.2016 had 53 contracts \n",
      "Fetched day 03.05.2016 had 0 contracts \n",
      "Fetched day 15.04.2016 had 48 contracts \n",
      "Fetched day 06.04.2016 had 54 contracts \n",
      "Fetched day 04.05.2016 had 25 contracts \n",
      "Fetched day 14.05.2016 had 0 contracts \n",
      "Fetched day 14.04.2016 had 63 contracts \n",
      "Fetched day 08.04.2016 had 60 contracts \n",
      "Fetched day 01.04.2016 had 57 contracts \n",
      "Fetched day 18.04.2016 had 58 contracts \n",
      "Fetched day 28.05.2016 had 0 contracts \n",
      "Fetched day 29.05.2016 had 0 contracts \n",
      "Fetched day 08.05.2016 had 0 contracts \n",
      "Fetched day 27.04.2016 had 67 contracts \n",
      "Fetched day 11.05.2016 had 49 contracts \n",
      "Fetched day 13.04.2016 had 70 contracts \n",
      "Fetched day 05.05.2016 had 58 contracts \n",
      "Fetched day 12.05.2016 had 50 contracts \n",
      "Fetched day 23.05.2016 had 47 contracts \n",
      "Fetched day 04.06.2016 had 0 contracts \n",
      "Fetched day 25.04.2016 had 51 contracts \n",
      "Fetched day 05.06.2016 had 0 contracts \n",
      "Fetched day 26.04.2016 had 78 contracts \n",
      "Fetched day 10.05.2016 had 45 contracts \n",
      "Fetched day 19.05.2016 had 53 contracts \n",
      "Fetched day 17.05.2016 had 49 contracts \n",
      "Fetched day 25.05.2016 had 54 contracts \n",
      "Fetched day 21.04.2016 had 60 contracts \n",
      "Fetched day 12.04.2016 had 48 contracts \n",
      "Fetched day 11.06.2016 had 0 contracts \n",
      "Fetched day 06.05.2016 had 54 contracts \n",
      "Fetched day 22.04.2016 had 47 contracts \n",
      "Fetched day 26.05.2016 had 59 contracts \n",
      "Fetched day 02.05.2016 had 0 contracts \n",
      "Fetched day 19.06.2016 had 0 contracts \n",
      "Fetched day 13.06.2016 had 0 contracts \n",
      "Fetched day 20.04.2016 had 67 contracts \n",
      "Fetched day 02.06.2016 had 52 contracts \n",
      "Fetched day 31.05.2016 had 71 contracts \n",
      "Fetched day 12.06.2016 had 0 contracts \n",
      "Fetched day 25.06.2016 had 0 contracts \n",
      "Fetched day 18.06.2016 had 0 contracts \n",
      "Fetched day 24.04.2016 had 0 contracts \n",
      "Fetched day 27.05.2016 had 70 contracts \n",
      "Fetched day 07.06.2016 had 45 contracts \n",
      "Fetched day 09.06.2016 had 49 contracts \n",
      "Fetched day 26.06.2016 had 0 contracts \n",
      "Fetched day 01.06.2016 had 50 contracts \n",
      "Fetched day 18.05.2016 had 45 contracts \n",
      "Fetched day 30.04.2016 had 0 contracts \n",
      "Fetched day 30.05.2016 had 60 contracts \n",
      "Fetched day 03.06.2016 had 50 contracts \n",
      "Fetched day 15.05.2016 had 5 contracts \n",
      "Fetched day 10.06.2016 had 61 contracts \n",
      "Fetched day 17.06.2016 had 54 contracts \n",
      "Fetched day 13.05.2016 had 67 contracts \n",
      "Fetched day 08.06.2016 had 65 contracts \n",
      "Fetched day 16.06.2016 had 61 contracts \n",
      "Fetched day 06.06.2016 had 41 contracts \n",
      "Fetched day 24.05.2016 had 57 contracts \n",
      "Fetched day 20.05.2016 had 60 contracts \n",
      "Fetched day 22.06.2016 had 58 contracts \n",
      "Fetched day 27.06.2016 had 55 contracts \n",
      "Fetched day 21.06.2016 had 63 contracts \n",
      "Fetched day 29.04.2016 had 78 contracts \n",
      "Fetched day 16.05.2016 had 47 contracts \n",
      "Fetched day 20.06.2016 had 60 contracts \n",
      "Fetched day 14.06.2016 had 48 contracts \n",
      "Fetched day 15.06.2016 had 54 contracts \n",
      "Fetched day 29.06.2016 had 57 contracts \n",
      "Fetched day 23.06.2016 had 42 contracts \n",
      "Fetched day 28.06.2016 had 56 contracts \n",
      "Fetched day 24.06.2016 had 56 contracts \n",
      "Fetched day 09.05.2016 had 0 contracts \n",
      "Fetched day 28.04.2016 had 93 contracts \n",
      "Fetched day 30.06.2016 had 74 contracts \n",
      "------------------- \n",
      " 3417 contracts found in total\n"
     ]
    }
   ],
   "source": [
    "### This part doesn't work, script is not going through pages, scrapes only first e.g. out of 3, \n",
    "### and doesn't save contract regnumbers \n",
    "## This now has regNumbers caching too \n",
    "\n",
    "cachedRegNums223 = {}\n",
    "\n",
    "# load the data from the json file\n",
    "with open('cachedRegNums223.json', 'r') as f:\n",
    "  cachedRegNums223 = json.load(f)\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=50) as ex:\n",
    "  for i, day in enumerate(calendar):\n",
    "    if day in cachedRegNums223:\n",
    "      regNumbersDict[day] = cachedRegNums223[day]\n",
    "      print(\"Cached day {} had {} contracts \\n\".format(day, len(regNumbersDict[day])), end='')\n",
    "    else:\n",
    "      ex.submit(getRegNumbersForDate, i, day)\n",
    "\n",
    "    \n",
    "combinedRegNumbersDict = {**cachedRegNums223, **regNumbersDict}\n",
    "\n",
    "# print(combinedRegNumbersDict)\n",
    "\n",
    "\n",
    "with open('cachedRegNums223.json', 'w') as f:\n",
    "  json.dump(combinedRegNumbersDict, f)\n",
    "\n",
    "\n",
    "tempRegNumbers = list(regNumbersDict.values())\n",
    "\n",
    "regNumbers = []\n",
    "\n",
    "for t in tempRegNumbers:\n",
    "  regNumbers.extend(t)\n",
    "\n",
    "# print(regNumbers)\n",
    "\n",
    "print(\"------------------- \\n {} contracts found in total\".format(len(regNumbers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L254l5YhpqNv"
   },
   "source": [
    "### Section 4: Details scraping\n",
    "\n",
    "The Contract Dataclass will store the information during scraping.\n",
    "If any information can't be scraped, default values have been provided in their place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Eg5Td-OGi3vz"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Contract:\n",
    "\n",
    "  # TODO: Add reg number to class\n",
    "\n",
    "  # Main Section\n",
    "  id: float = 0\n",
    "  price: float = 0.0\n",
    "  signed: date = None\n",
    "  # deadline: date = None\n",
    "\n",
    "  # Tab 1\n",
    "  method: str = \"none\"\n",
    "  procurer: str = \"none\"\n",
    "  # supplier: str = \"none\"\n",
    "  proinn: str = \"none\"\n",
    "  # supinn: str = \"none\"\n",
    "  # registered: date = None\n",
    "  person: str= \"none\"\n",
    "  address: str = \"none\"\n",
    "  number: str = \"none\"\n",
    "  mail: str = \"none\"\n",
    "\n",
    "  # Tab 2\n",
    "  code: float = 0.0\n",
    "  product: str = \"none\"\n",
    "  \n",
    "\n",
    "  def __repr__(self):\n",
    "    return \"\\nContract id= {} \\n First tab: price={}, signed={}, method={}, procurer={}, proinn={}, person={}, address={}, number={}, mail={}, product={} \\n  Second tab: code={})\".format(self.id, self.price, self.signed, self.method, self.procurer, self.proinn, self.person, self.address, self.number, self.mail, self.product, self.code)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yatvXkvpz2H"
   },
   "source": [
    "Method for scraping the data from each contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSectionDict(page):\n",
    "\n",
    "    sections=page.findAll(\"div\",{\"class\":\"col-9 mr-auto\"})\n",
    "\n",
    "    # print([key.findAll(\"span\") for key in sections])\n",
    "\n",
    "    # Turning the sections into a dictionary that will be easier to work with.\n",
    "    pairs = [key.findAll(\"div\") for key in sections]\n",
    "\n",
    "    pairs = list(filter(None, pairs))\n",
    "\n",
    "\n",
    "    titles = []\n",
    "    values = []\n",
    "\n",
    "    for x in pairs:\n",
    "        if len(x) > 1:\n",
    "            try:\n",
    "                titles.append(x[0])\n",
    "                values.append(x[1])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    sectionDict = {titles[i].text.strip() : values[i].text.strip() for i in range(len(titles))}\n",
    "\n",
    "    return sectionDict\n",
    "\n",
    "\n",
    "# def getTableDict(page, secondTab=False):\n",
    "\n",
    "\n",
    "#     if secondTab:\n",
    "#         sectionOfInterest = page.findAll(\"div\", {\"class\": \"col\"})[-1]\n",
    "#     else:\n",
    "#         sectionOfInterest = page\n",
    "\n",
    "#     table = sectionOfInterest.findAll(\"tr\",{\"class\":\"tableBlock__row\"})\n",
    "\n",
    "#     # print(table[3])\n",
    "\n",
    "#     headers = [i.text.strip() for i in table[0].findAll(\"th\", {\"class\":\"tableBlock__col tableBlock__col_header\"})]\n",
    "#     data = [list(filter(None, [j.strip() for j in i.text.split(\"\\n\")])) for i in table[1].findAll(\"td\")]\n",
    "\n",
    "#     if len(headers) == 0:\n",
    "#         headers = [i.text.strip() for i in table[2].findAll(\"th\", {\"class\":\"tableBlock__col tableBlock__col_header\"})]\n",
    "#         data = [list(filter(None, [j.strip() for j in i.text.split(\"\\n\")])) for i in table[3].findAll(\"td\")]\n",
    "\n",
    "#     if len(headers) == 0:\n",
    "#         headers = [i.text.strip() for i in table[3].findAll(\"th\", {\"class\":\"tableBlock__col tableBlock__col_header\"})]\n",
    "#         data = [list(filter(None, [j.strip() for j in i.text.split(\"\\n\")])) for i in table[4].findAll(\"td\")]\n",
    "\n",
    "\n",
    "\n",
    "#     # This is hacky.\n",
    "#     if len(data) < len(headers):\n",
    "#         data = [[[]] for i in range(len(headers))]\n",
    "\n",
    "        \n",
    "\n",
    "#     tableDict = {headers[i] : data[i] for i in range(len(headers))}\n",
    "\n",
    "#     return tableDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Jq9BLFkUaDPW"
   },
   "outputs": [],
   "source": [
    "def scrapeData(reg):\n",
    "\n",
    "  try:\n",
    "    # Input: reg = one registration number.\n",
    "\n",
    "    # Different URL from the one above, this accesses more information from Zakupki.\n",
    "    dir=\"https://zakupki.gov.ru/epz/order/notice/notice223/{}.html?noticeInfoId={}\"\n",
    "    #\"https://zakupki.gov.ru/epz/contract/contractCard/{}.html?reestrNumber={}\"\n",
    "\n",
    "    # Getting the web page for the given contract\n",
    "    tempDir = dir.format(\"common-info\", reg)\n",
    "    page = getPage(tempDir)\n",
    "\n",
    "    # We probably don't need this with the method I've used below.\n",
    "    # contractTypeTwo = False\n",
    "\n",
    "    # Enter the text here that should be present to signify the second type of contract.\n",
    "    # if page.findAll(text=\"Основание заключения контракта с единственным поставщиком\"):\n",
    "    #   contractTypeTwo = True\n",
    "      \n",
    "    id = reg  \n",
    "    sectionDict = getSectionDict(page)\n",
    "    # firstTableDict = getTableDict(page)\n",
    "\n",
    "    # print(sectionDict)\n",
    "    # print(firstTableDict)\n",
    "\n",
    "    # print(sectionDict, firstTableDict)\n",
    "    # try:\n",
    "    #   price=sectionDict[\"Цена контракта\"].replace(\"\\xa0\",\"\").replace(\",\",\".\").replace(\"₽\",\"\").strip().split()[0]\n",
    "    # except:\n",
    "    #   price=sectionDict[\"Ориентировочное значение цены контракта\"].replace(\"\\xa0\",\"\").replace(\",\",\".\").replace(\"₽\",\"\").strip().split()[0]\n",
    "    #   try:\n",
    "    #     price=sectionDict[\"Максимальное значение цены контракта\"].replace(\"\\xa0\",\"\").replace(\",\",\".\").replace(\"₽\",\"\").strip().split()[0]\n",
    "    #   except:\n",
    "    try:\n",
    "      price=page.find('div', {'class':'price-block__value'}).text.strip().replace(\"₽\",\"\").replace(\",\",\".\").replace(\" \", \"\")\n",
    "    except: \n",
    "      price=\"\"\n",
    "    try:\n",
    "      signed=page.find('div',{'class':'data-block__value'}).text.strip()\n",
    "    except:\n",
    "      signed=\"\"\n",
    "    # deadline=sectionDict[\"Дата окончания исполнения контракта\"].split()[0]\n",
    "    \n",
    "    ### fixed issue with method ### \n",
    "    try:\n",
    "      method = sectionDict[\"Способ осуществления закупки\"]\n",
    "    except:\n",
    "      if page.findAll(text=\"Основание заключения контракта с единственным поставщиком\"):\n",
    "            method=\"Закупка у единственного поставщика (подрядчика, исполнителя)\"\n",
    "            \n",
    "    try:\n",
    "      procurer=sectionDict[\"Наименование организации\"]\n",
    "    except:\n",
    "      if page.findAll(text=\"Полное наименование заказчика\"):\n",
    "            procurer=\"Полное наименование заказчика\"\n",
    "    # supplier=firstTableDict[\"Организация\"][0]\n",
    "\n",
    "    proinn=page.find('div', {'class':'ml-1 common-text__value'}).text.strip()\n",
    "\n",
    "    ### fixed issues for missing values sometimes in the table ###\n",
    "    \n",
    "    # registered=firstTableDict[\"Организация\"][-1]\n",
    "    \n",
    "    ### fixed, testing ###   \n",
    "    # try: \n",
    "    #   if firstTableDict[\"Организация\"][-4]==\"КПП:\":\n",
    "    #       supinn=firstTableDict[\"Организация\"][-5]\n",
    "    #   else:\n",
    "    #       supinn=firstTableDict[\"Организация\"][-3]\n",
    "    # except:\n",
    "    #   supinn=\"\"\n",
    "\n",
    "    ### fixed issues in lower table ### \n",
    "    try:\n",
    "      address=sectionDict['Место нахождения']\n",
    "    except:\n",
    "      address=\"\"\n",
    "    try:\n",
    "      mail=sectionDict['Адрес электронной почты']\n",
    "    except:\n",
    "      mail=\"\"\n",
    "    number=sectionDict['Контактный телефон']\n",
    "    try:\n",
    "      product=sectionDict['Наименование закупки']\n",
    "    except:\n",
    "      product=\"\"\n",
    "    try:\n",
    "      person=sectionDict['Контактное лицо']\n",
    "    except:\n",
    "      person=\"\"\n",
    "\n",
    "\n",
    "    ### details about winner - ALSO, THERE'S OPTION TO SCRAPE SUBCONTRACTORS ### \n",
    "\n",
    "    page.decompose()\n",
    "\n",
    "    ### Second tab ###\n",
    "    tempDir = dir.format(\"lot-list\", reg)\n",
    "    page = getPage(tempDir)\n",
    "\n",
    "    ### code stands for the product code, which can be later identified to return industry type ### \n",
    "    \n",
    "    # secondTableDict = getTableDict(page, True)\n",
    "    \n",
    "    codetablevalues=page.findAll({\"td\":\"class\"})\n",
    "    \n",
    "    try:\n",
    "      code = code=codetablevalues[3].text.strip().split(' ')[0]\n",
    "    except:\n",
    "      code = ''\n",
    "        \n",
    "    # product = secondTableDict[\"Наименование объекта закупки и его характеристики\"][0]\n",
    "    \n",
    "    # Create the Contract dataclass object and append it to a list of objects.\n",
    "    # This method means that missing data can be accounted for.\n",
    "    # print(method)\n",
    "\n",
    "    contract = Contract(id=id, price=price, signed=signed, method=method, procurer=procurer, proinn=proinn, address=address, person=person, number=number, mail=mail, code=code, product=product)\n",
    "    \n",
    "    # contracts.append(contract)\n",
    "    # print('Completed {}'.format(id))\n",
    "\n",
    "    page.decompose()\n",
    "\n",
    "    return contract\n",
    "  except Exception as e:\n",
    "    failedRegNumbers.append(reg)\n",
    "    print(\"Failed to scrape {}\".format(reg))\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CitfSwF2p94x"
   },
   "source": [
    "### Section 5: Starting execution\n",
    "Scrape the contracts themselves using threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(reg):\n",
    "    \n",
    "    try:\n",
    "        _ = int(reg)\n",
    "        # print(\"Scraping {}\".format(reg))\n",
    "        return [scrapeData(reg)]\n",
    "    except TypeError:\n",
    "        \n",
    "        # TODO make 500 contracts change here.\n",
    "        \n",
    "        contracts = []\n",
    "\n",
    "        \n",
    "\n",
    "        for idx, r in enumerate(reg):\n",
    "            # print(\"Scraping {}\".format(r))\n",
    "            contracts.append(scrapeData(r))\n",
    "            # progress(i + idx, regNumbers)\n",
    "\n",
    "        return contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RseKcK3_XT7R",
    "outputId": "2e193036-25a2-4b02-8d91-34a6293d9141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scrape with 3417 reg numbers\n",
      "\n",
      "3417 of 3417 contracts are uncached. Fetching...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3417it [1:00:11,  1.06s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 1 contracts\n",
      "Failed to scrape 0 contracts\n",
      "Top 3 lines\n",
      "#1: lib\\ast.py:50: 10233.1 KiB\n",
      "    return compile(source, filename, mode, flags,\n",
      "#2: <string>:1: 7919.6 KiB\n",
      "#3: ipykernel_25088\\3405311262.py:4: 7703.0 KiB\n",
      "    cachedContracts = list(csv.reader(f))\n",
      "3069 other: 61544.0 KiB\n",
      "Total allocated size: 87399.8 KiB\n"
     ]
    }
   ],
   "source": [
    "progressNum = 0\n",
    "\n",
    "failedRegNumbers = []\n",
    "\n",
    "# regNumbers = [14511297]\n",
    "\n",
    "print(\"Starting scrape with {} reg numbers\\n\".format(len(regNumbers)))\n",
    "\n",
    "# scrape(regNumbers[:10])\n",
    "\n",
    "# for contract in contracts:\n",
    "#     print(contract)\n",
    "\n",
    "# for regNumber in tqdm(regNumbers[:50]):\n",
    "#   thread = Thread(target = scrapeData, args = (regNumber,))\n",
    "#   thread.start()\n",
    "\n",
    "# regNumbers = ['3662502457421000001']\n",
    "# regNumbers = ['1665800691921000016']\n",
    "\n",
    "threading = True\n",
    "\n",
    "if threading:\n",
    "\n",
    "    interval = 1\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=20) as ex:\n",
    "        threads = []\n",
    "\n",
    "        cachedContracts = {}\n",
    "\n",
    "        with open('cachedContracts.csv', encoding=\"utf-8\") as f:\n",
    "            cachedContracts = list(csv.reader(f))\n",
    "        \n",
    "        cachedContracts = list(filter(None, cachedContracts))\n",
    "        \n",
    "        cachedContractRegNums = [row[0] for row in cachedContracts]\n",
    "\n",
    "        uncachedRegNumbers = list(set(regNumbers) - set(cachedContractRegNums))\n",
    "\n",
    "        print(\"{} of {} contracts are uncached. Fetching...\".format(len(uncachedRegNumbers), len(regNumbers)))\n",
    "        \n",
    "        for i in range(0, len(uncachedRegNumbers), interval):\n",
    "            tempNumbers = uncachedRegNumbers[i:i+interval]\n",
    "            # print(tempNumbers)\n",
    "            threads.append(ex.submit(scrape, tempNumbers))\n",
    "        \n",
    "\n",
    "        completed = 0\n",
    "\n",
    "        for result in tqdm(as_completed(threads)):\n",
    "\n",
    "            try:\n",
    "                contracts = result.result()\n",
    "\n",
    "                completed += interval\n",
    "\n",
    "                # progress(completed, uncachedRegNumbers)\n",
    "\n",
    "                formattedContracts = [list(contract.__dict__.values()) for contract in contracts]\n",
    "\n",
    "                # newCachedContracts = {**cachedContracts, **formattedContracts}\n",
    "\n",
    "                with open('cachedContracts.csv', 'a', encoding=\"utf-8\", newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerows(formattedContracts)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "            # print(\"{} finished\".format(interval))\n",
    "\n",
    "else:\n",
    "\n",
    "    scrape(regNumbers)\n",
    "\n",
    "print(\"Scraped {} contracts\".format(len(contracts)))\n",
    "print(\"Failed to scrape {} contracts\".format(len(failedRegNumbers)))\n",
    "print(failedRegNumbers) if len(failedRegNumbers) > 0 else None\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "display_top(snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the data is saved to the hard disk, we can run the below code without needing to rerun the scraping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-01 2016-06-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29.12.2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20.03.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28.12.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18.06.2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23.01.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13.02.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14.07.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15.07.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21.09.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13.07.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23.04.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18.07.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21.05.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22.07.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17.10.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19.06.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20.07.2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "c:\\Users\\majda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24.01.2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>signed</th>\n",
       "      <th>method</th>\n",
       "      <th>procurer</th>\n",
       "      <th>proinn</th>\n",
       "      <th>person</th>\n",
       "      <th>address</th>\n",
       "      <th>number</th>\n",
       "      <th>mail</th>\n",
       "      <th>code</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4070538</td>\n",
       "      <td>3 500 000.00</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>Закупка у единственного поставщика (исполнител...</td>\n",
       "      <td>АКЦИОНЕРНОЕ ОБЩЕСТВО \"УРАЛЬСКИЙ ЗАВОД ТРАНСПОР...</td>\n",
       "      <td>6659190900</td>\n",
       "      <td>Холманских Е.Е.</td>\n",
       "      <td>620017, Свердловская обл, г Екатеринбург, р-н ...</td>\n",
       "      <td>+7 (3435) 977180</td>\n",
       "      <td>holmanskihE@ubtuvz.ru</td>\n",
       "      <td>21.20.23.111</td>\n",
       "      <td>Поставка медицинских реагентов для лабораторно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3933327</td>\n",
       "      <td>1 473 072.00</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>открытый запрос предложений</td>\n",
       "      <td>ОТКРЫТОЕ АКЦИОНЕРНОЕ ОБЩЕСТВО \"МЕЖРЕГИОНАЛЬНАЯ...</td>\n",
       "      <td>6671163413</td>\n",
       "      <td>Ложкарев а.Д.</td>\n",
       "      <td>620026, ОБЛАСТЬ СВЕРДЛОВСКАЯ, Г. ЕКАТЕРИНБУРГ,...</td>\n",
       "      <td>+7 (343) 2152554</td>\n",
       "      <td>Lozhkarev-AD@mrsk-ural.ru</td>\n",
       "      <td>71.12.13.000</td>\n",
       "      <td>Право заключения договора на разработку проект...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4068813</td>\n",
       "      <td>3 330 400.00</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>Открытый конкурс</td>\n",
       "      <td>МУНИЦИПАЛЬНОЕ АВТОНОМНОЕ ОБЩЕОБРАЗОВАТЕЛЬНОЕ У...</td>\n",
       "      <td>6602007212</td>\n",
       "      <td>Ильманова С.И.</td>\n",
       "      <td>623780, ОБЛАСТЬ СВЕРДЛОВСКАЯ,РАЙОН АРТЕМОВСКИЙ...</td>\n",
       "      <td>+343 (63) 21406</td>\n",
       "      <td>school12art@mail.ru</td>\n",
       "      <td>56.29.20.120</td>\n",
       "      <td>оказание услуг по организации питания учащихся</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4351364</td>\n",
       "      <td>10 219 308.00</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>Открытый конкурс</td>\n",
       "      <td>МУНИЦИПАЛЬНОЕ АВТОНОМНОЕ УЧРЕЖДЕНИЕ \"ДЕТСКИЙ З...</td>\n",
       "      <td>6603016107</td>\n",
       "      <td>Стафеева Л.В.</td>\n",
       "      <td>624285, ОБЛАСТЬ СВЕРДЛОВСКАЯ,ПОСЕЛОК ГОРОДСКОГ...</td>\n",
       "      <td>+8 (34365) 99366</td>\n",
       "      <td>iskorkamou@mail.ru</td>\n",
       "      <td>56.29.20.190</td>\n",
       "      <td>Оказание услуги по организации горячего питани...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3803152</td>\n",
       "      <td>1 800 000.00</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>Закупка у единственного поставщика (исполнител...</td>\n",
       "      <td>МУНИЦИПАЛЬНОЕ АВТОНОМНОЕ УЧРЕЖДЕНИЕ ГОРОДСКОГО...</td>\n",
       "      <td>6620015110</td>\n",
       "      <td>Бирюкова  А.В.</td>\n",
       "      <td>624330, ОБЛ СВЕРДЛОВСКАЯ,Г КРАСНОУРАЛЬСК,УЛ СО...</td>\n",
       "      <td>+8 (34343) 27121</td>\n",
       "      <td>dkbuh@list.ru</td>\n",
       "      <td>4030020</td>\n",
       "      <td>Оказание услуг теплоснабжения в количестве и с...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id           price     signed  \\\n",
       "7   4070538   3 500 000.00  2016-04-03   \n",
       "17  3933327   1 473 072.00  2016-04-02   \n",
       "20  4068813   3 330 400.00  2016-04-03   \n",
       "23  4351364  10 219 308.00  2016-04-05   \n",
       "25  3803152   1 800 000.00  2016-06-01   \n",
       "\n",
       "                                               method  \\\n",
       "7   Закупка у единственного поставщика (исполнител...   \n",
       "17                        открытый запрос предложений   \n",
       "20                                   Открытый конкурс   \n",
       "23                                   Открытый конкурс   \n",
       "25  Закупка у единственного поставщика (исполнител...   \n",
       "\n",
       "                                             procurer      proinn  \\\n",
       "7   АКЦИОНЕРНОЕ ОБЩЕСТВО \"УРАЛЬСКИЙ ЗАВОД ТРАНСПОР...  6659190900   \n",
       "17  ОТКРЫТОЕ АКЦИОНЕРНОЕ ОБЩЕСТВО \"МЕЖРЕГИОНАЛЬНАЯ...  6671163413   \n",
       "20  МУНИЦИПАЛЬНОЕ АВТОНОМНОЕ ОБЩЕОБРАЗОВАТЕЛЬНОЕ У...  6602007212   \n",
       "23  МУНИЦИПАЛЬНОЕ АВТОНОМНОЕ УЧРЕЖДЕНИЕ \"ДЕТСКИЙ З...  6603016107   \n",
       "25  МУНИЦИПАЛЬНОЕ АВТОНОМНОЕ УЧРЕЖДЕНИЕ ГОРОДСКОГО...  6620015110   \n",
       "\n",
       "             person                                            address  \\\n",
       "7   Холманских Е.Е.  620017, Свердловская обл, г Екатеринбург, р-н ...   \n",
       "17    Ложкарев а.Д.  620026, ОБЛАСТЬ СВЕРДЛОВСКАЯ, Г. ЕКАТЕРИНБУРГ,...   \n",
       "20   Ильманова С.И.  623780, ОБЛАСТЬ СВЕРДЛОВСКАЯ,РАЙОН АРТЕМОВСКИЙ...   \n",
       "23    Стафеева Л.В.  624285, ОБЛАСТЬ СВЕРДЛОВСКАЯ,ПОСЕЛОК ГОРОДСКОГ...   \n",
       "25   Бирюкова  А.В.  624330, ОБЛ СВЕРДЛОВСКАЯ,Г КРАСНОУРАЛЬСК,УЛ СО...   \n",
       "\n",
       "              number                       mail          code  \\\n",
       "7   +7 (3435) 977180      holmanskihE@ubtuvz.ru  21.20.23.111   \n",
       "17  +7 (343) 2152554  Lozhkarev-AD@mrsk-ural.ru  71.12.13.000   \n",
       "20   +343 (63) 21406        school12art@mail.ru  56.29.20.120   \n",
       "23  +8 (34365) 99366         iskorkamou@mail.ru  56.29.20.190   \n",
       "25  +8 (34343) 27121              dkbuh@list.ru       4030020   \n",
       "\n",
       "                                              product  \n",
       "7   Поставка медицинских реагентов для лабораторно...  \n",
       "17  Право заключения договора на разработку проект...  \n",
       "20     оказание услуг по организации питания учащихся  \n",
       "23  Оказание услуги по организации горячего питани...  \n",
       "25  Оказание услуг теплоснабжения в количестве и с...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cachedContracts = []\n",
    "\n",
    "with open('cachedContracts.csv', encoding=\"utf-8\") as f:\n",
    "    cachedContracts = list(csv.reader(f))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=Contract().__dict__.keys(), data=cachedContracts)\n",
    "\n",
    "df['signed'] = pd.to_datetime(df['signed'])\n",
    "# df['deadline'] = pd.to_datetime(df['deadline'])\n",
    "\n",
    "start = datetime.fromordinal(startDateBefore.toordinal()).strftime(\"%Y-%m-%d\")\n",
    "end = datetime.fromordinal(endDate.toordinal()).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(start, end)\n",
    "\n",
    "mask = (df['signed'] >= start) & (df['signed'] <= end)\n",
    "\n",
    "selectedDatesDF = df.loc[mask]\n",
    "\n",
    "selectedDatesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2833, 12)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedDatesDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9_G7hUrqT6g"
   },
   "source": [
    "### Section 6: Output\n",
    "\n",
    "Convert the list of contract classes to a dataframe so that they can be exported to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "9ST7Qk4rVOFK"
   },
   "outputs": [],
   "source": [
    "selectedDatesDF.to_csv(\"zakupki{}to{}.csv\".format(startDateBefore, endDate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Zakupki.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "77edd9a980bfddd358a4fcbf4f3e7f49f98b43dd432ee51433ccfac9d125dab6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
